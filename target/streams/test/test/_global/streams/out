[0m[[0m[0mdebug[0m] [0m[0mjavaOptions: Vector(--add-opens=java.base/java.io=ALL-UNNAMED, --add-opens=java.base/java.nio=ALL-UNNAMED, --add-opens=java.base/sun.nio.ch=ALL-UNNAMED, --add-opens=java.base/sun.nio.cs=ALL-UNNAMED, --add-opens=java.base/sun.security.action=ALL-UNNAMED, --add-opens=java.base/sun.util.calendar=ALL-UNNAMED, --add-exports=java.base/sun.nio.ch=ALL-UNNAMED)[0m
[0m[[0m[0mdebug[0m] [0m[0mForking tests - parallelism = false[0m
[0m[[0m[0mdebug[0m] [0m[0mCreate a single-thread test executor[0m
[0m[[0m[0mdebug[0m] [0m[0mRunner for org.scalatest.tools.Framework produced 2 initial tasks for 2 tests.[0m
[0m[[0m[0mdebug[0m] [0m[0m  Running TaskDef(org.apache.spark.ml.made.StartSparkTest, sbt.ForkMain$SubclassFingerscan@5ce81285, false, [SuiteSelector])[0m
[0m[[0m[0minfo[0m] [0m[0m[32mStartSparkTest:[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mSpark[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[33m- should start context !!! IGNORED !!![0m[0m
[0m[[0m[0mdebug[0m] [0m[0m    Produced 0 nested tasks and 1 events.[0m
[0m[[0m[0mdebug[0m] [0m[0m  Running TaskDef(org.apache.spark.ml.made.LinRegTest, sbt.ForkMain$SubclassFingerscan@78c03f1f, false, [SuiteSelector])[0m
[0m[[0m[0minfo[0m] [0m[0m[32mLinRegTest:[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mModel[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32m- should can predict[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEstimator[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should calculate weights and bias *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  2.883038895271183 was not 1.5 plus or minus 0.01 (LinRegTest.scala:113)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEstimator[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should should produce functional model *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  java.lang.ArrayIndexOutOfBoundsException: Index 2 out of bounds for length 2[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.expressions.GenericRow.get(rows.scala:174)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.Row.getAs(Row.scala:362)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.Row.getAs$(Row.scala:362)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.sql.catalyst.expressions.GenericRow.getAs(rows.scala:166)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.ml.made.LinRegTest.$anonfun$new$5(LinRegTest.scala:54)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at org.apache.spark.ml.made.LinRegTest.$anonfun$new$5$adapted(LinRegTest.scala:54)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  ...[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEstimator[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32m- should not learn with 0 iterations[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEstimator[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32m- should not learn with 0 learning rate[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEstimator[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32m- should not learn with negative learning rate[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mEstimator[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should work after re-read *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  2.883038895271183 was not 1.5 plus or minus 0.01 (LinRegTest.scala:113)[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[32mModel[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m- should work after re-read *** FAILED ***[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m  2.883038895271183 was not 1.5 plus or minus 0.01 (LinRegTest.scala:113)[0m[0m
[0m[[0m[0mdebug[0m] [0m[0m    Produced 0 nested tasks and 8 events.[0m
[0m[[0m[0minfo[0m] [0m[0m[36mRun completed in 3 minutes, 33 seconds.[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mTotal number of tests run: 8[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mSuites: completed 2, aborted 0[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[36mTests: succeeded 4, failed 4, canceled 0, ignored 1, pending 0[0m[0m
[0m[[0m[0minfo[0m] [0m[0m[31m*** 4 TESTS FAILED ***[0m[0m
[0m[[0m[0mdebug[0m] [0m[0mPassed tests:[0m
[0m[[0m[0mdebug[0m] [0m[0m	org.apache.spark.ml.made.StartSparkTest[0m
[0m[[0m[31merror[0m] [0m[0mFailed tests:[0m
[0m[[0m[31merror[0m] [0m[0m	org.apache.spark.ml.made.LinRegTest[0m
[0m[[0m[31merror[0m] [0m[0m(Test / [31mtest[0m) sbt.TestsFailedException: Tests unsuccessful[0m
